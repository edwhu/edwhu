Hi, I'm Edward. Currently, I'm interested in developing data-driven methods that interact, explore, and learn from the world. My research investigates deep reinforcement learning, perception, and robotics

### ðŸ¤–&nbsp; Research Artifacts
Here are the codebases of my research projects so far.

|     |     |     |
| :-: | :-: | :-- |
| [scaffolder](https://github.com/penn-pal-lab/scaffolder) | ![](https://img.shields.io/github/stars/penn-pal-lab/scaffolder?label=%E2%98%85) | Privileged Sensing Scaffolds RL __(ICLR'24 Spotlight)__ |
| [planning goals for exploration](https://github.com/penn-pal-lab/peg) | ![](https://img.shields.io/github/stars/penn-pal-lab/peg?label=%E2%98%85) | Planning Goals for Exploration __(ICLR'23 Spotlight)__|
| [interactive reward functions](https://github.com/penn-pal-lab/interactive_reward_functions) | ![](https://img.shields.io/github/stars/penn-pal-lab/interactive_reward_functions?label=%E2%98%85) | Training Robots to Evaluate Robots __(CoRL'22 Best Paper Award)__ |
| [robot aware control](https://github.com/penn-pal-lab/robot_aware_control) | ![](https://img.shields.io/github/stars/penn-pal-lab/robot_aware_control?label=%E2%98%85) | Know Thyself: Transferable Visual Control Policies Through Robot-Awareness (ICLR'22) |
| [ikea furniture simulation](https://github.com/clvrai/furniture) | ![](https://img.shields.io/github/stars/clvrai/furniture?label=%E2%98%85) | IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks (ICRA'21) |




### Nerd stuff
I like studying codebases that are elegantly written and do cool things. Some topics that I found interesting lately: [dataloading at scale](https://www.moderndescartes.com/essays/shuffle_viz/), [Jax renderer](https://github.com/JoeyTeng/jaxrenderer), [Jax Monte-Carlo Tree Search library](https://github.com/google-deepmind/mctx).  
Some of my side projects:
|     |     |     |
| :-: | :-: | :-- |
| [gpt2 slackbot](https://github.com/edwhu/slack-gpt2) | ![](https://img.shields.io/github/stars/edwhu/slack-gpt2?label=%E2%98%85) | Chatting with GPT2 in slack |
| [optical illusion](https://github.com/edwhu/optical_illusion) | ![](https://img.shields.io/github/stars/edwhu/optical_illusion?label=%E2%98%85) | A cool optical illusion |


<details>
  <summary><i></i>Something to think about as an ML researcher</i></summary>
  I think researchers start out very pure hearted, but can easily end up misled and lost. The incentives of the modern research community, particularly ML, are misaligned with doing good science. To employ an analogy, ML is currently like a hackathon. You are incentivized to put together an MVP that works just enough to pass the appraisal of the judges. You feel obligated to use the shiny new "X" because it will garner public attention. Companies with free t-shirts and kickbacks swarm around you.  

Yes, some of these things are unavoidable. But if you blindly follow the noise, you may end up in the eye of the storm - at a standstill, with no exit in sight.

![Ant Death Spiral](https://github.com/edwhu/edwhu/blob/master/ant_spiral.gif)

Don't be distracted by the noise!

</details>
